{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG_all_in_one.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CZ2RMYU-Bq5Z","colab_type":"code","outputId":"8c0ccd50-0539-4016-8135-6af059785640","executionInfo":{"status":"ok","timestamp":1558443020895,"user_tz":-120,"elapsed":700,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PE9-LTOSGlFE","colab_type":"text"},"source":["# create data VGG\n","## import libraries"]},{"cell_type":"code","metadata":{"id":"JX9a0DilGseU","colab_type":"code","outputId":"e79d40c8-bf5d-44a5-df3c-3a53059c6082","executionInfo":{"status":"ok","timestamp":1558464013154,"user_tz":-120,"elapsed":2132,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","from keras.models import Sequential\n","from keras.models import load_model\n","from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda\n","from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed\n","from keras.layers import AveragePooling2D, Input\n","from keras.utils import np_utils, normalize\n","from keras.engine import InputLayer\n","from keras import backend as K\n","\n","import os\n","import h5py\n","import time\n","\n","import sklearn\n","from sklearn.preprocessing import normalize\n","import random\n","\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing import image\n","from keras.applications.vgg19 import preprocess_input\n","from keras.models import Model\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import confusion_matrix\n","\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import math"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"VvQGxHOEaCvZ","colab_type":"text"},"source":["## modifiable variables"]},{"cell_type":"code","metadata":{"id":"o36IqCrHG4Ev","colab_type":"code","outputId":"fdba41d1-7602-41ba-ae71-85bb5a94f517","executionInfo":{"status":"ok","timestamp":1558464017418,"user_tz":-120,"elapsed":512,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# dataset's name \n","doc = 'chest_xray'\n","# if the dataset is splited\n","is_splited = True\n","# test size for dataset unsplited\n","test_size = 0.2\n","# if a dataset contains validation set\n","has_val = False\n","\n","# paths to load datasets and to save the model\n","dir_path = 'drive/My Drive/medical_image_recognition/datasets/'\n","save_path = 'drive/My Drive/medical_image_recognition/notebooks_Chen/'\n","model_path = 'drive/My Drive/medical_image_recognition/models/'\n","\n","# paths\n","# vgg_fold='datanp_vgg/'\n","vgg_fold='vgg19_trained/'\n","kmeans_fold=\"kmeans_PCA/\"\n","vlad_fold=\"vlad_fold/\"\n","\n","# model\n","flag_load_model = True\n","model_with_structure = True\n","# model type name and weights' path\n","model_name = 'vgg19' # vgg19, vgg19custom, vgg16, vgg16custom\n","model_file_name = 'model_1_model.hdf5'\n","\n","# feature extraction parameters\n","scales=[2]\n","layers=['fc2']\n","pooling = 'max'\n","\n","# if save vectors in differents files in case the RAM is insufficient\n","vgg_multi_files = True\n","RAM_SIZE = 8 * 1024 * 1024 * 1024 #GPU RAM in Byte\n","\n","flag_VLAD = False\n","\n","#Kmeans\n","k_descriptors=30\n","\n","print('Done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AXmVg4Zkxzfu","colab_type":"text"},"source":["## file path check"]},{"cell_type":"code","metadata":{"id":"83FLC321xzPm","colab_type":"code","outputId":"ecb60994-ed07-4ea3-a0db-49fe347d578a","executionInfo":{"status":"ok","timestamp":1558464019832,"user_tz":-120,"elapsed":762,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dir_path_DataSet = dir_path + doc + '/'\n","save_path_Dataset = save_path + doc + '/'\n","\n","vgg_path = save_path_Dataset+'/'+vgg_fold\n","kmeans_path = save_path_Dataset+'/'+ \"kmeans_PCA/\"\n","vlad_path = save_path_Dataset+'/'+ \"vlad_fold/\"\n","model_file_path = model_path + doc + '/' + model_file_name\n","\n","os.system('mkdir -p {}'.format(vgg_path))\n","if flag_VLAD:\n","  os.system('mkdir -p {} {}'.format(kmeans_path, vlad_path))\n","  \n","if flag_load_model:\n","  if not os.path.exists(model_file_path):\n","    print('model file not existe')\n","  else:\n","    print('Done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["model file not existe\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6A52bjjpEMoW","colab_type":"text"},"source":["## image process functions"]},{"cell_type":"code","metadata":{"id":"ApvEsuE5HPmg","colab_type":"code","outputId":"a359fc49-300d-4dc4-cdf1-02aeb6f2c490","executionInfo":{"status":"ok","timestamp":1558464024473,"user_tz":-120,"elapsed":1575,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def read_dir(dir_path):\n","  \"\"\"return the differents categories, the images in these categories, and the number of images per category\"\"\"\n","  listDir = sorted(os.listdir(dir_path))\n","  size = 0\n","  listFiles = []\n","  Y = []\n","  for d in listDir :\n","    files = sorted(os.listdir(dir_path+'/'+d))\n","    size += len(files)\n","    files = [dir_path+'/'+d+'/'+f for f in files]\n","    Y += [d] * len(files)\n","    listFiles += files\n","  return listFiles, Y, size\n","\n","def dir_train_test_split(listFiles, Y):\n","  random.seed(42)\n","  test_index = random.sample(list(range(len(listFiles))), int(test_size*len(listFiles)))\n","  train_index = [x for x in list(range(len(listFiles))) if x not in test_index]\n","  \n","  listFiles_train = [listFiles[i] for i in train_index]\n","  listFiles_test = [listFiles[i] for i in test_index]\n","  Y_train = [Y[i] for i in train_index]\n","  Y_test = [Y[i] for i in test_index]\n","  return listFiles_train, Y_train, listFiles_test, Y_test\n","\n","def create_zero_array(layer, n, nb_images_left, nbImagesPerFile):\n","  \"\"\"return a numpy array with zeros and with the needed scales\"\"\"\n","  nb = min(nb_images_left, nbImagesPerFile)\n","  if layer == 'block5_pool' or layer == 'vgg19':\n","    X = np.zeros((nb, 7 + 10*n, 7 + 10*n, 512))\n","  else :\n","    if n == 0 :\n","      X = np.zeros((nb, 4096))\n","#       X = np.zeros((nb, 512))\n","    else :\n","#       X = np.zeros((nb, 1 + 10*n, 1 + 10*n, 4096))\n","      X = np.zeros((nb, 1 + 20*n, 1 + 20*n, 512))\n","  return X\n","\n","\n","def complete_array_cancer(files, X_new, Y, n, n_image) :\n","  \"\"\"for all the images in listFiles, extract the features thanks to the network\"\"\"\n","  \"\"\"return a 4-dimensional array with a 3-dimensional array per image\"\"\"\n","  nb = 0\n","  cpt = 0\n","  t0 = time.time()\n","  print(len(files))\n","  nb += len(files)\n","  Y_new = []\n","  cpt_X = 0\n","  for f in files :\n","    if cpt < n_image:\n","      cpt += 1\n","      continue\n","    if cpt_X == X_new.shape[0]:\n","        break\n","    t1 = time.time()\n","    img = image.load_img(f, target_size=(224 + 320*n, 224 + 320*n))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    features = model.predict(x)\n","    X_new[cpt_X,:] = features[0,:]\n","    Y_new.append(Y[cpt])\n","    cpt += 1\n","    cpt_X += 1\n","    t2 = time.time()\n","    print('complete array{}/{}, time: {}s'.format(cpt,nb, t2-t1))\n","  print('total', t2 - t0)\n","  return X_new, Y_new\n","\n","def to_fully_conv(model):\n","  \"\"\"transforms the Convolutional Neural Network model into a Fully Convolutional Network\"\"\"\n","\n","  new_model = Sequential()\n","  input_layer = InputLayer(input_shape=(None, None, 3), name=\"input_new\")\n","  new_model.add(input_layer)\n","\n","  for layer in model.layers:\n","\n","    if \"Flatten\" in str(layer):\n","      flattened_ipt = True\n","      f_dim = layer.input_shape\n","      continue\n","\n","    elif \"Dense\" in str(layer):\n","\n","      input_shape = layer.input_shape\n","      output_dim =  layer.get_weights()[1].shape[0]\n","      W,b = layer.get_weights()\n","\n","      if flattened_ipt:\n","          shape = (f_dim[1],f_dim[2],f_dim[3],output_dim)\n","          new_W = W.reshape(shape)\n","          aa = np.array([new_W,b])\n","          new_layer = Convolution2D(output_dim,(f_dim[1],f_dim[2]),\n","                                    activation=layer.activation,\n","                                    padding='valid', weights=[new_W,b])\n","          flattened_ipt = False\n","\n","      else:\n","          shape = (1,1,input_shape[1],output_dim)\n","          new_W = W.reshape(shape)\n","          new_layer = Convolution2D(output_dim,(1,1),\n","                                    activation=layer.activation,\n","                                    padding='valid', weights=[new_W,b])\n","    else:\n","      new_layer = layer\n","    new_model.add(new_layer)\n","    \n","  return new_model\n","\n","def pool(X, p):\n","  \"\"\"return the numpy array X on which the pooling p was performed\"\"\"\n","  if(len(X.shape) == 2):\n","    return X\n","  if p == 'max' :  \n","    X_pool = np.max(X, axis = (1, 2)) \n","  elif p == 'mean' :\n","    X_pool = np.mean(X, axis = (1, 2)) \n","  else :\n","    X_pool = X\n","  return X_pool\n","\n","def cal_nbSaveFiles(layer, n, size_train, size_test, size_val = 0):\n","  if layer == 'block5_pool':\n","    size_image = 8*(7+10*n)*(7+10*n)*512\n","  else:\n","    size_image = 8*(1+10*n)*(1+10*n)*4096\n","    \n","  nbSaveFiles_train = math.ceil(size_image * size_train / RAM_SIZE * 2)\n","  nbSaveFiles_test = math.ceil(size_image * size_test / RAM_SIZE * 2)\n","  nbSaveFiles_val = math.ceil(size_image * size_val / RAM_SIZE * 2)\n","  nbImagesPerFile = int(RAM_SIZE / 2 // size_image)\n","  return nbImagesPerFile, nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val\n","\n","\n","#path where the output array will be saved\n","def get_vector_files_path(flag_VLAD, vgg_multi_files, save_path, doc, layer, n, pooling, nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val):\n","  \n","  path_save_train = []\n","  path_save_test = []\n","  path_save_val = []\n","  path_save_Y_train = []\n","  path_save_Y_test = []\n","  path_save_Y_val = []\n","    \n","  if flag_VLAD == False:\n","    for i in range(nbSaveFiles_train):\n","      path_save_train.append(  save_path + 'X_train_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","      path_save_Y_train.append(save_path + 'y_train_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","    for i in range(nbSaveFiles_test):\n","      path_save_test.append(  save_path + 'X_test_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","      path_save_Y_test.append(save_path + 'y_test_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","    for i in range(nbSaveFiles_val):\n","      path_save_val.append(  save_path + 'X_val_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","      path_save_Y_val.append(save_path + 'y_val_' + layer + '_' + pooling + '(' + str(n) + ')'+ str(i)+'.npy')\n","  else:\n","    if vgg_multi_files:\n","      for i in range(nbSaveFiles_train):\n","        path_save_train.append(  save_path + 'X_train_' + layer + '(' + str(n) + ')'+ str(i)+'.npy')\n","        path_save_Y_train.append(save_path + 'y_train_' + layer + '(' + str(n) + ')'+str(i)+'.npy')\n","      for i in range(nbSaveFiles_test):\n","        path_save_test.append(  save_path + 'X_test_' + layer + '(' + str(n) + ')' + str(i)+'.npy')\n","        path_save_Y_test.append(save_path + 'y_test_' + layer + '(' + str(n) + ')' + str(i)+'.npy')\n","      for i in range(nbSaveFiles_val):\n","        path_save_val.append(  save_path + 'X_val_' + layer + '(' + str(n) + ')' + str(i)+'.npy')\n","        path_save_Y_val.append(save_path + 'y_val_' + layer + '(' + str(n) + ')' + str(i)+'.npy')\n","  return path_save_train, path_save_Y_train, path_save_test, path_save_Y_test, path_save_val, path_save_Y_val\n","\n","print('Done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QZCD-aJS0YuC","colab_type":"text"},"source":["## costum neural network definition"]},{"cell_type":"code","metadata":{"id":"p8cuTudu0YgR","colab_type":"code","colab":{}},"source":["def load_full_model(model_file_path):\n","  model = load_model(model_file_path)\n","  return model\n","\n","def get_cnn_model(model_name: str):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    if model_name == 'vgg16':\n","        return create_vgg16()\n","    elif model_name == 'vgg16custom':\n","        return create_vgg16custom()\n","    elif model_name == 'vgg19':\n","        return create_vgg19()\n","    elif model_name == 'vgg19custom':\n","        return create_vgg19custom()\n","    else:\n","        raise ValueError(\n","                'The model {} isn\\'t implemented yet'.format(model_name))\n","\n","################################################################################\n","def create_vgg16():\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    base_model = VGG16(include_top=False,\n","                             weights='imagenet',\n","                             input_shape=(HEIGHT, WIDTH, CHANNELS))\n","\n","    model = Sequential()\n","    model.add(base_model)\n","\n","    # add classification block\n","    model.add(Flatten(name='flatten'))\n","    model.add(Dense(1024, activation='relu', name='fc1'))\n","    model.add(Dropout(0.7, name='dropout1'))\n","    model.add(Dense(512, activation='relu', name='fc2'))\n","    model.add(Dropout(0.5, name='dropout2'))\n","    model.add(Dense(NUM_LABELS, activation='softmax', name='predictions'))\n","\n","    # see the base model architecture\n","    #base_model.summary()\n","\n","    return model\n","\n","################################################################################\n","def create_vgg16custom():\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    img_input = Input(shape=(HEIGHT, WIDTH, CHANNELS), name='ImageInput')\n","\n","    # block 1\n","    x = Conv2D(64, (3, 3),\n","               activation='relu',\n","               padding='same',\n","               name='block1_conv1')(img_input)\n","    x = Conv2D(64, (3, 3),\n","               activation='relu',\n","               padding='same',\n","               name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), name='block1_pool')(x)\n","\n","    #TODO\n","    # variables to change for SeparableConv2D\n","    # no activation in xception\n","    # use_bias=False\n","\n","    # block 2\n","    x = SeparableConv2D(128, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block2_conv1')(x)\n","    x = SeparableConv2D(128, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), name='block2_pool')(x)\n","\n","    # block 3\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        #use_bias=False,\n","                        name='block3_conv1')(x)\n","    x = BatchNormalization(name='block3_conv1_bn')(x)\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        #use_bias=False,\n","                        name='block3_conv2')(x)\n","    x = BatchNormalization(name='block3_conv2_bn')(x)\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), name='block3_pool')(x)\n","\n","    # block 4\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv1')(x)\n","    x = BatchNormalization(name='block4_conv1_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv2')(x)\n","    x = BatchNormalization(name='block4_conv2_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), name='block4_pool')(x)\n","\n","    # block 5\n","    # TODO\n","\n","    # classification block\n","    x = Flatten(name='flatten')(x)\n","    x = Dense(1024, activation='relu', name='fc1')(x) #4096\n","    x = Dropout(0.7, name='dropout1')(x) # not present\n","    x = Dense(512, activation='relu', name='fc2')(x) # 4096\n","    x = Dropout(0.5, name='dropout2')(x) # not present\n","    x = Dense(NUM_LABELS, activation='softmax', name='predictions')(x)\n","\n","    # create the cnn\n","    model = Model(img_input, x, name='vgg16_custom')\n","\n","    # !!! WEIGHTS !!!\n","    weights_path = MODEL_PATH + 'weights_notop.h5'\n","    print('Trying to load weights from {} ...'.format(weights_path))\n","    \n","    ### TODO cleaner\n","    from pathlib import Path\n","    weights_path = Path(weights_path)\n","    if not weights_path.is_file():\n","        vgg16_model = VGG16(weights='imagenet', include_top=False)\n","        vgg16_model.save_weights(weights_path)\n","\n","    # load weights\n","    model.load_weights(weights_path, by_name=True)\n","    print('DONE')\n","    return model\n","\n","################################################################################\n","def create_vgg19():\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    base_model = VGG19(include_top=False,\n","                             weights='imagenet',\n","                             input_shape=(HEIGHT, WIDTH, CHANNELS))\n","\n","    model = Sequential()\n","    model.add(base_model)\n","\n","    # add classification block\n","    model.add(Flatten(name='flatten'))\n","    model.add(Dense(1024, activation='relu', name='fc1'))\n","    model.add(Dropout(0.7, name='dropout1'))\n","    model.add(Dense(512, activation='relu', name='fc2'))\n","    model.add(Dropout(0.5, name='dropout2'))\n","    model.add(Dense(NUM_LABELS, activation='softmax', name='predictions'))\n","\n","    #base_model.summary()\n","    #model.summary()\n","\n","    return model\n","\n","################################################################################\n","def create_vgg19custom():\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    \n","    #TODO\n","    # variables to change for SeparableConv2D\n","    # no activation in xception\n","    # use_bias=False\n","    \n","    img_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n","\n","    # block 1\n","    # it's exactly the same as in vgg19\n","    x = Conv2D(64, (3, 3),\n","               activation='relu',\n","               padding='same',\n","               name='block1_conv1')(img_input)\n","    x = Conv2D(64, (3, 3),\n","               activation='relu',\n","               padding='same',\n","               name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # block 2\n","    x = SeparableConv2D(128, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block2_conv1')(x)\n","    x = SeparableConv2D(128, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), name='block2_pool')(x)\n","\n","    # block 3\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        #use_bias=False,\n","                        name='block3_conv1')(x)\n","    x = BatchNormalization(name='block3_conv1_bn')(x)\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        #use_bias=False,\n","                        name='block3_conv2')(x)\n","    x = BatchNormalization(name='block3_conv2_bn')(x)\n","    x = SeparableConv2D(256, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), name='block3_pool')(x)\n","\n","    # block 4\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv1')(x)\n","    x = BatchNormalization(name='block4_conv1_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv2')(x)\n","    x = BatchNormalization(name='block4_conv2_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), name='block4_pool')(x)\n","\n","    # block 5\n","    # TODO\n","\n","    # classification block\n","    x = Flatten(name='flatten')(x)\n","    x = Dense(1024, activation='relu', name='fc1')(x) #4096\n","    x = Dropout(0.7, name='dropout1')(x) # not present\n","    x = Dense(512, activation='relu', name='fc2')(x) # 4096\n","    x = Dropout(0.5, name='dropout2')(x) # not present\n","    x = Dense(NUM_LABELS, activation='softmax', name='predictions')(x)\n","\n","    #TODO load weights here\n","\n","    model = Model(img_input, x, name='vgg19custom')\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYdp6vuvO9J4","colab_type":"text"},"source":["## prepare data"]},{"cell_type":"code","metadata":{"id":"frtw3x-ypoGG","colab_type":"code","colab":{}},"source":["#split train test examples\n","if is_splited:\n","  dir_path_train = dir_path_DataSet + 'train/'\n","  dir_path_test =  dir_path_DataSet + 'test/'\n","  listFiles_train, Y_train, size_train = read_dir(dir_path_train)\n","  listFiles_test, Y_test, size_test = read_dir(dir_path_test)\n","\n","  if has_val:\n","    dir_path_val =  dir_path_DataSet + '/val/'\n","    listFiles_val, Y_val, size_val = read_dir(dir_path_val)\n","\n","\n","else:\n","  listFiles, Y, size = read_dir(dir_path_DataSet)\n","  listFiles_train, Y_train, listFiles_test, Y_test = dir_train_test_split(listFiles, Y)\n","  size_train = len(listFiles_train)\n","  size_test = len(listFiles_test)\n","  has_val = False\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPans8jJdudP","colab_type":"code","outputId":"f0f5913e-d588-44bb-f07f-78600ad03d3e","executionInfo":{"status":"ok","timestamp":1558458627568,"user_tz":-120,"elapsed":2009,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(listFiles_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5221"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"OMdxoduwVf6c","colab_type":"text"},"source":["## generate vectors and save in files"]},{"cell_type":"code","metadata":{"id":"b7VmAFISUZ1n","colab_type":"code","colab":{}},"source":["def vector_generator(Y_, size, nbSaveFiles, listFiles, path_save, path_save_Y):\n","  for i in range(nbSaveFiles):\n","    X = create_zero_array(layer, n, size-i*nbImagesPerFile, nbImagesPerFile)\n","    \n","    X, Y = complete_array_cancer(listFiles, X, Y_, n, i*nbImagesPerFile)\n","    if not flag_VLAD:\n","      X = pool(X, pooling)\n","    np.save(path_save[i], X)\n","    np.save(path_save_Y[i], Y)\n","    del X\n","    print('{}th file saved'.format(i))\n","    \n","def get_model(layer):\n","  if flag_load_model:\n","    if model_with_structure:\n","      network = load_full_model(model_file_path)\n","    else:\n","      network = get_cnn_model(model_name)\n","      network.load_weights(model_file_path)\n","  else:\n","    network = VGG19(weights='imagenet')\n","  model = Model(inputs=network.input, outputs=network.get_layer(layer).get_output_at(-1))\n","  if n >= 1 : \n","    model = to_fully_conv(model)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6ZevstsHYTh","colab_type":"code","outputId":"49cd60d4-9a3a-4ecb-bc94-fdbaba4a64ef","executionInfo":{"status":"error","timestamp":1558464033336,"user_tz":-120,"elapsed":1115,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":506}},"source":["for layer in layers:\n","  for n in scales: \n","    if vgg_multi_files:\n","      nbImagesPerFile, nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val = cal_nbSaveFiles(layer, n, size_train, size_test)\n","    else:\n","      nbImagesPerFile, nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val = max(size_train, size_test), 1, 1, 1\n","      if not has_val:\n","        nbSaveFiles_val = 0\n","      \n","    HEIGHT, WIDTH, CHANNELS = 224, 224, 3\n","    NUM_LABELS = len(set(Y_train))\n","    \n","    \n","    model = get_model(layer)\n","    print(\"layer = \" + layer + \" n = \" + str(n) )\n","    \n","    path_save_train, path_save_Y_train, path_save_test, \\\n","    path_save_Y_test, path_save_val, path_save_Y_val = get_vector_files_path(flag_VLAD, vgg_multi_files, \n","                                                                             vgg_path, doc, layer, n, pooling, \n","                                                                             nbSaveFiles_train, nbSaveFiles_test,\n","                                                                             nbSaveFiles_val)\n","\n","    vector_generator(Y_train, size_train, nbSaveFiles_train, listFiles_train, path_save_train, path_save_Y_train)\n","    vector_generator(Y_test, size_test, nbSaveFiles_test, listFiles_test, path_save_test, path_save_Y_test)\n","    if has_val:\n","      vector_generator(Y_val, size_val, nbSaveFiles_val, listFiles_val, path_save_val, path_save_Y_val)\n","    \n","\n","    del model\n","print('Done')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1af7fc142ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" n = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-6768a36b5869>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mflag_load_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_with_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_full_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-44253be80030>\u001b[0m in \u001b[0;36mload_full_model\u001b[0;34m(model_file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_full_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'drive/My Drive/medical_image_recognition/models/chest_xray/model_1_model.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"cell_type":"code","metadata":{"id":"9ac6twCI8mMc","colab_type":"code","outputId":"5c98db0d-f7bb-4cb7-bb99-ee57eb901e9d","executionInfo":{"status":"ok","timestamp":1558267763314,"user_tz":-120,"elapsed":1962,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(Y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6400"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"DxLMpYLugPtX","colab_type":"text"},"source":["# SVM without VLAD"]},{"cell_type":"code","metadata":{"id":"DQPWgi4tWugN","colab_type":"code","colab":{}},"source":["def load_vectors(layer, n, size_train, size_test):\n","  nbImagesPerFile, nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val = cal_nbSaveFiles(layer, n, size_train, size_test)\n","#   nbSaveFiles_train, nbSaveFiles_test, nbSaveFiles_val = 1, 1, 0\n","  path_save_train, path_save_Y_train, path_save_test, \\\n","  path_save_Y_test, path_save_val, path_save_Y_val = get_vector_files_path(flag_VLAD, vgg_multi_files, \n","                                                                             vgg_path, doc, layer, n, pooling, \n","                                                                             nbSaveFiles_train, nbSaveFiles_test,\n","                                                                             nbSaveFiles_val)\n","\n","  Y_train = np.load(path_save_Y_train[0])\n","  Y_test = np.load(path_save_Y_test[0])\n","  X_train = np.load(path_save_train[0])\n","  X_test = np.load(path_save_test[0])\n","  for i in range(1, nbSaveFiles_train):\n","    X_train = np.concatenate((X_train, np.load(path_save_train[i])))\n","    Y_train = np.concatenate((Y_train, np.load(path_save_Y_train[i])))\n","  for i in range(1, nbSaveFiles_test):\n","    X_test = np.concatenate((X_test, np.load(path_save_test[i])))\n","    Y_test = np.concatenate((Y_test, np.load(path_save_Y_test[i])))\n","  return X_train, X_test, Y_train, Y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2ErDJ1WpiCF","colab_type":"code","outputId":"fadc70a1-50d9-4631-c53d-77d3691fadd5","executionInfo":{"status":"ok","timestamp":1558462931407,"user_tz":-120,"elapsed":314995,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from sklearn import svm\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","if flag_VLAD == False:\n","  for layer in layers:\n","    for n in scales:\n","      print('layer: {}, scale: {}'.format(layer, n))\n","      X_train, X_test, Y_train, Y_test = load_vectors(layer, n, size_train, size_test)\n","      \n","#       normalization\n","      X_train = normalize(X_train, norm = 'l2', axis = 1)\n","      X_test = normalize(X_test, norm = 'l2', axis = 1)\n","\n","      \"\"\"SUPPORT VECTOR MACHINE\"\"\"\n","\n","      parameters = {'C':[0.00001,0.0001,0.001,0.01, 0.1, 1, 10,100]}\n","      svc = svm.SVC(kernel='linear')\n","      clf = GridSearchCV(svc, parameters, cv=3)\n","      clf.fit(X_train, Y_train)\n","      \n","#       print('train set Accuracy: %.2f' % clf.score(X_train, Y_train))\n","      Y_pred = clf.predict(X_test)\n","      try:\n","        cm  = confusion_matrix(Y_test, Y_pred)\n","        tn, fp, fn, tp= cm.ravel()\n","        precision = tp / (tp + fp)\n","        recall =    tp / (tp + fn)\n","        accuracy = (tp + tn) / (tn + fp + fn + tp)\n","\n","        print(\"Recall of the model is {:.5f}\".format(recall))\n","        print(\"Precision of the model is {:.5f}\".format(precision))\n","        print(\"Accuracy of the model is {:.5f}\".format(accuracy))\n","      except:\n","        print(accuracy_score(Y_test, Y_pred))\n","        \n","      print('best params: {}'.format(clf.best_params_))\n","      print('Done')\n","      \n","print('Done')\n","\n","      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["layer: fc2, scale: 1\n","Recall of the model is 0.99487\n","Precision of the model is 0.70674\n","Accuracy of the model is 0.73878\n","best params: {'C': 100}\n","Done\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6dKxuQdJeU1Y","colab_type":"code","outputId":"cfa704ea-bf49-4556-9d85-4077d1fbc5d5","executionInfo":{"status":"ok","timestamp":1558342889541,"user_tz":-120,"elapsed":431,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":116}},"source":["len(X_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5049"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"FBuTX6Ld_F9-","colab_type":"text"},"source":["# SVM with VLAD\n","## Kmeans"]},{"cell_type":"code","metadata":{"id":"Vm5ok-8KCeHR","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","import sklearn\n","from sklearn.preprocessing import normalize\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import numpy as np\n","\n","def save_file(path,obj):\n","  pickle_out = open(path,\"wb\")\n","  pickle.dump(obj, pickle_out)\n","  pickle_out.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQ49zDe2GITF","colab_type":"code","outputId":"4bf6bebc-9dce-4787-8647-90b81bb64f93","executionInfo":{"status":"error","timestamp":1558443776186,"user_tz":-120,"elapsed":682,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["for layer in layers:\n","  for n in scales:\n","    print(\"layer = \" + layer + \" n = \" + str(n) )\n","    X=np.load(vgg_path + 'X_train_'+layer + '(' + str(n) + ').npy')\n","\n","    #this just for miniMIT bc we don't have many descriptorts \n","    if doc=='miniMIT_Etus':\n","      if len(X.shape) == 4:\n","        k_descriptors = X.shape[1]*X.shape[2]\n","      else:\n","        k_descriptors = 1\n","\n","    #reshape (d1,d2,d3,d4) -> (d1,d2*d3,d4)\n","    if len(X.shape) == 4:\n","      d=X.shape[1]*X.shape[2]\n","      X = np.reshape(X,(X.shape[0],d,X.shape[3]))\n","    else:\n","      d = 1\n","      X = np.reshape(X,(X.shape[0],d,X.shape[1]))\n","\n","    #we take only some discriptors\n","    if doc!='miniMIT_Etus':\n","      #take random descriptors\n","      indexes = np.arange(d)\n","      np.random.shuffle(indexes)\n","      indexes=indexes[:k_descriptors]\n","      X=X[:,indexes,:]\n","\n","    if(n==0):\n","      x_all=X[:]\n","    else:\n","      x_all=np.concatenate((x_all,X),axis=1)\n","    del X\n","\n","  x_all=np.reshape(x_all,(x_all.shape[0]*x_all.shape[1],x_all.shape[2]))\n","  \n","  x_all = sklearn.preprocessing.normalize(x_all, norm = 'l2', axis = 1)\n","\n","  x_all = StandardScaler(with_std=False).fit_transform(x_all)\n","\n","  x_all = sklearn.preprocessing.normalize(x_all, norm = 'l2', axis = 1)\n","  \n","  print(\"PCA fit transform ...\")\n","  pca = PCA(n_components=128)\n","  x_train = pca.fit_transform(x_all)\n","  \n","  x_train = sklearn.preprocessing.normalize(x_train, norm = 'l2', axis = 1)\n","\n","  #kmeans\n","  print(\"Kmean1 64 ...\")\n","  kmeans1 = KMeans(n_clusters=64, random_state=0).fit(x_train)\n","  print(\"Kmean2 256 ...\")\n","  kmeans2 = KMeans(n_clusters=256, random_state=0).fit(x_train)\n","\n","  #save pca, kmeans  pickle\n","  save_file(kmeans_path+'_'+layer+'_'+'PCA.pickle',pca)\n","  save_file(kmeans_path+'_'+layer+'_'+'kmean1.pickle',kmeans1)\n","  save_file(kmeans_path+'_'+layer+'_'+'kmean2.pickle',kmeans2)\n","        \n","  del x_all\n","print(\"END\")\n","      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["layer = fc1 n = 0\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-c54875f97400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" n = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'X_train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m').npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#this just for miniMIT bc we don't have many descriptorts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/medical_image_recognition/notebooks_Chen/miniMIT_Etus//datanp_vgg/X_train_fc1(0).npy'"]}]},{"cell_type":"markdown","metadata":{"id":"k6rGIzc-OrfL","colab_type":"text"},"source":["## VLAD"]},{"cell_type":"code","metadata":{"id":"66KxFx7iOsXu","colab_type":"code","colab":{}},"source":["import sklearn\n","from sklearn.cluster import KMeans\n","import numpy as np\n","from sklearn.svm import SVC\n","import pickle\n","from sklearn.preprocessing import normalize\n","from sklearn.decomposition import PCA\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ff5bXp-sO5ce","colab_type":"code","colab":{}},"source":["def VLAD(X,visualDictionary):\n","\n","  predictedLabels = visualDictionary.predict(X)\n","  centers = visualDictionary.cluster_centers_\n","  labels=visualDictionary.labels_\n","  k=visualDictionary.n_clusters\n","\n","  m,d = X.shape\n","  V=np.zeros([k,d])\n","  #computing the differences\n","\n","  # for all the clusters (visual words)\n","  for i in range(k):\n","    # if there is at least one descriptor in that cluster\n","    if np.sum(predictedLabels==i)>0:\n","      # add the diferences\n","      V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\n","\n","  V = V.flatten()\n","  # power normalization\n","  V = np.sign(V)*np.sqrt(np.abs(V))\n","\n","  # L2 normalization\n","  V = V/np.sqrt(np.dot(V,V))\n","  return V\n","  \n","def get_vlad(layer,scales,kmean1,kmean2,pca,type_set=\"train\"):\n","  for n in scales:\n","    print(n , layer)\n","    #laod_data\n","    if type_set==\"train\":\n","      x=np.load(vgg_path +'X_train_'+layer + '(' + str(n) + ').npy')\n","    elif type_set==\"test\":\n","      x=np.load(vgg_path +'X_test_'+layer + '(' + str(n) + ').npy')\n","\n","\n","    #reshape (d1,d2,d3,d4) -> (d1,d2*d3,d4)\n","    if len(x.shape) == 4:\n","      x = np.reshape(x,(x.shape[0],(x.shape[1]*x.shape[2]),x.shape[3]))\n","    else:\n","      x = np.reshape(x,(x.shape[0],1,x.shape[1]))\n","\n","    #if x_all is empty : x_all take x else add data to x_all \n","    if(n==0):\n","      x_all=x\n","    else:\n","      x_all=np.concatenate((x_all,x),axis=1)\n","                \n","    \n","    V_64=[]\n","    V_256=[]\n","    #for ech image\n","    for vec in x_all:\n","      #we take the first vec and we delete it from the data set: memory problem\n","      x_all=x_all[1:,...]\n","      #normalization l2\n","      vec = normalize(vec, norm = 'l2', axis = 1)\n","      #transformation with PCA\n","      vec=pca.transform(vec)\n","      #normalisation\n","      vec = normalize(vec, norm = 'l2', axis = 1)\n","\n","\n","      V_64.append(VLAD(vec,kmean1))\n","      V_256.append(VLAD(vec,kmean2))\n","    \n","    return V_64,V_256"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmfFGiTLPCmA","colab_type":"code","outputId":"0170332e-c882-49d2-ed19-5ff35c687460","executionInfo":{"status":"ok","timestamp":1557151395465,"user_tz":-120,"elapsed":147175,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["for layer in layers:\n","  print('loading files')\n","  kmean1 = pickle.load(open(kmeans_path+'_'+layer+'_'+'kmean1.pickle', 'rb'))\n","  kmean2 = pickle.load(open(kmeans_path+'_'+layer+'_'+'kmean2.pickle', 'rb'))\n","  pca = pickle.load(open(kmeans_path+'_'+layer+'_'+'PCA.pickle', 'rb'))\n","\n","  print('VLAD for train set')\n","  v_train_64,v_train_256=get_vlad(layer,scales,kmean1,kmean2,pca,type_set=\"train\")\n","  v_train_64 = np.asarray(v_train_64)\n","  v_train_256= np.asarray(v_train_256)\n","\n","  np.save(vlad_path+'_'+layer+'_'+'vlad_train(64).npy',v_train_64)\n","  np.save(vlad_path+'_'+layer+'_'+'vlad_train(256).npy',v_train_256)\n","  del v_train_64,v_train_256\n","\n","  print('VLAD for test set')\n","  v_test_64,v_test_256=get_vlad(layer,scales,kmean1,kmean2,pca,type_set=\"test\")\n","  v_test_64 = np.asarray(v_test_64)\n","  v_test_256= np.asarray(v_test_256)\n","\n","  np.save(vlad_path+'_'+layer+'_'+'vlad_test(64).npy',v_test_64)\n","  np.save(vlad_path+'_'+layer+'_'+'vlad_test(256).npy',v_test_256)\n","  del v_test_64,v_test_256\n","\n","  print(\"done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 block5_pool\n","1 block5_pool\n","2 block5_pool\n","(171, 8192)\n","0 block5_pool\n","1 block5_pool\n","2 block5_pool\n","(73, 8192)\n","done\n","0 fc1\n","1 fc1\n","2 fc1\n","(171, 8192)\n","0 fc1\n","1 fc1\n","2 fc1\n","(73, 8192)\n","done\n","0 fc2\n","1 fc2\n","2 fc2\n","(171, 8192)\n","0 fc2\n","1 fc2\n","2 fc2\n","(73, 8192)\n","done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8XGGKeSGRSlx","colab_type":"text"},"source":["## SVM"]},{"cell_type":"code","metadata":{"id":"zO_2G9SgRVIs","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pkes3h32Rjix","colab_type":"code","outputId":"2c6b10ce-6d21-412f-e475-56137f3f80fc","executionInfo":{"status":"ok","timestamp":1557152069150,"user_tz":-120,"elapsed":170334,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["for layer in layers:\n","  print('prediction SVM [%s]' %(layer))\n","  \n","  v_train_64 = np.load(vlad_path+'_'+layer+'_'+'vlad_train(64).npy')\n","  v_train_256= np.load(vlad_path+'_'+layer+'_'+'vlad_train(256).npy')\n","  v_test_64  = np.load(vlad_path+'_'+layer+'_'+'vlad_test(64).npy')\n","  v_test_256 = np.load(vlad_path+'_'+layer+'_'+'vlad_test(256).npy')\n","\n","  y_train=np.load(vgg_path + 'Y_train_'+layer + '(' + str(0) + ').npy')\n","  y_test=np.load( vgg_path + 'Y_test_' +layer + '(' + str(0) + ').npy')\n","  \n","  parameters = {'C':[0.0001,0.001,0.01, 0.1, 1, 10,100]}\n","  \n","  print('SUPPORT VECTOR MACHINE 256')\n","  clf = SVC(kernel='linear')\n","  clf = GridSearchCV(clf, parameters, cv=3)\n","  clf.fit(v_train_256, y_train)\n","  print('Accuracy vlad 256: %.2f' % clf.score(v_test_256, y_test))\n","  \n","  print('SUPPORT VECTOR MACHINE 64')\n","  clf = SVC(kernel='linear')\n","  clf = GridSearchCV(clf, parameters, cv=3)\n","  clf.fit(v_train_64, y_train)\n","  print('Accuracy vlad 64: %.2f' % clf.score(v_test_64, y_test))        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["(171, 8192)\n","(171, 32768)\n","SUPPORT VECTOR MACHINE 256\n","Accuracy vlad 256: 0.74\n","prediction SVM [block5_pool]\n","SUPPORT VECTOR MACHINE 64\n","Accuracy vlad 64: 0.77\n","(171, 8192)\n","(171, 32768)\n","SUPPORT VECTOR MACHINE 256\n","Accuracy vlad 256: 0.71\n","prediction SVM [fc1]\n","SUPPORT VECTOR MACHINE 64\n","Accuracy vlad 64: 0.77\n","(171, 8192)\n","(171, 32768)\n","SUPPORT VECTOR MACHINE 256\n","Accuracy vlad 256: 0.74\n","prediction SVM [fc2]\n","SUPPORT VECTOR MACHINE 64\n","Accuracy vlad 64: 0.79\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ybaCjCobgYTE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}