{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. vlad.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"d2u8ZP2EcUMc","colab_type":"code","outputId":"cfabef98-744e-4aab-f25e-8f86f14ad83a","executionInfo":{"status":"ok","timestamp":1557093744175,"user_tz":-120,"elapsed":535,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmklVZHvjQeD","colab_type":"code","colab":{}},"source":["import sklearn\n","from sklearn.cluster import KMeans\n","import numpy as np\n","from sklearn.svm import SVC\n","import pickle\n","from sklearn.preprocessing import normalize\n","from sklearn.decomposition import PCA\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CAtyT_0jQeR","colab_type":"code","colab":{}},"source":["def VLAD(X,visualDictionary):\n","\n","    predictedLabels = visualDictionary.predict(X)\n","    centers = visualDictionary.cluster_centers_\n","    labels=visualDictionary.labels_\n","    k=visualDictionary.n_clusters\n","\n","    m,d = X.shape\n","    \n","    \n","    V=np.zeros([k,d])\n","    #computing the differences\n","\n","    # for all the clusters (visual words)\n","    for i in range(k):\n","        # if there is at least one descriptor in that cluster\n","        if np.sum(predictedLabels==i)>0:\n","            # add the diferences\n","            V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\n","\n","\n","    V = V.flatten()\n","    # power normalization, also called square-rooting normalization\n","    V = np.sign(V)*np.sqrt(np.abs(V))\n","\n","    # L2 normalization\n","\n","    V = V/np.sqrt(np.dot(V,V))\n","    \n","    return V"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhKCKlM2jQeY","colab_type":"code","colab":{}},"source":["def get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"train\"):\n","    for n in scales:\n","        print(doc, n , layer)\n","        #laod_data\n","        if type_set==\"train\":\n","            x=np.load(dir_path_DataSet + doc + '/' + load_fold + doc +'X_train_'+layer + '(' + str(n) + ').npy')\n","        elif type_set==\"test\":\n","            x=np.load(dir_path_DataSet + doc + '/' + load_fold + doc +'X_test_'+layer + '(' + str(n) + ').npy')\n","            \n","\n","        #reshape (d1,d2,d3,d4) -> (d1,d2*d3,d4)\n","        if len(x.shape) == 4:\n","          x = np.reshape(x,(x.shape[0],(x.shape[1]*x.shape[2]),x.shape[3]))\n","        else:\n","          x = np.reshape(x,(x.shape[0],1,x.shape[1]))\n","\n","        #if x_all is empty : x_all take x else add data to x_all \n","        if(n==0):\n","            x_all=x\n","        else:\n","            x_all=np.concatenate((x_all,x),axis=1)\n","                \n","    \n","    V_64=[]\n","    V_256=[]\n","    #for ech image\n","    for vec in x_all:\n","        #we take the first vec and we delete it from the data set: memory problem\n","        x_all=x_all[1:,...]\n","        #normalization l2\n","        vec = normalize(vec, norm = 'l2', axis = 1)\n","        #transformation with PCA\n","        vec=pca.transform(vec)\n","        #normalisation\n","        vec = normalize(vec, norm = 'l2', axis = 1)\n","        \n","        \n","        V_64.append(VLAD(vec,kmean1))\n","        V_256.append(VLAD(vec,kmean2))\n","\n","    \n","    return V_64,V_256\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOxOc1FkjQeg","colab_type":"code","colab":{}},"source":["load_fold='datanp_vgg/'\n","#dataset's path \n","dir_path_DataSet = 'drive/My Drive/medical_image_recognition/datasets/'\n","\n","#fold name for saving files(kmean/PCA)\n","fold_name=\"k_means_PCA/\"\n","vlad_fold=\"vlad_fold/\"\n","\n","docs=['miniMIT_Etus']#,'chest_xray','kvasir-dataset-v2']\n","scales=[0]\n","layers=['fc1','fc2']#,'block8_9_conv']#,'block8_8_conv']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qLqLoZIHP_dm","colab_type":"text"},"source":["# n=1,2,3 ensemble"]},{"cell_type":"code","metadata":{"id":"Glf9Kdp2jQen","colab_type":"code","outputId":"befd230d-de92-4e8c-86b3-e4293cdeeda3","executionInfo":{"status":"ok","timestamp":1557094483612,"user_tz":-120,"elapsed":143312,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["for doc in docs:\n","    for layer in layers:\n","        #load files \n","        kmean1 = pickle.load(open(dir_path_DataSet+doc+'/'+fold_name+doc+'_'+layer+'_'+'kmean1.pickle', 'rb'))\n","        kmean2 = pickle.load(open(dir_path_DataSet+doc+'/'+fold_name+doc+'_'+layer+'_'+'kmean2.pickle', 'rb'))\n","        pca = pickle.load(open(dir_path_DataSet+doc+'/'+fold_name+doc+'_'+layer+'_'+'PCA.pickle', 'rb'))\n","        \n","        #lead file for train set\n","        v_train_64,v_train_256=get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"train\")\n","        v_train_64 = np.asarray(v_train_64)\n","        v_train_256= np.asarray(v_train_256)\n","        \n","        print(v_train_64.shape)\n","        np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'vlad_train(64).npy',v_train_64)\n","        np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'vlad_train(256).npy',v_train_256)\n","        del v_train_64,v_train_256\n","        \n","        #for test set\n","        v_test_64,v_test_256=get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"test\")\n","        \n","        v_test_64 = np.asarray(v_test_64)\n","        v_test_256= np.asarray(v_test_256)\n","        print(v_test_64.shape)\n","        #save vlad files\n","        np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'vlad_test(64).npy',v_test_64)\n","        np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'vlad_test(256).npy',v_test_256)\n","        \n","        print(\"done\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["miniMIT_Etus 0 block5_pool\n","miniMIT_Etus 1 block5_pool\n","miniMIT_Etus 2 block5_pool\n","(120, 8192)\n","miniMIT_Etus 0 block5_pool\n","miniMIT_Etus 1 block5_pool\n","miniMIT_Etus 2 block5_pool\n","(120, 8192)\n","done\n","miniMIT_Etus 0 fc1\n","miniMIT_Etus 1 fc1\n","miniMIT_Etus 2 fc1\n","(120, 8192)\n","miniMIT_Etus 0 fc1\n","miniMIT_Etus 1 fc1\n","miniMIT_Etus 2 fc1\n","(120, 8192)\n","done\n","miniMIT_Etus 0 fc2\n","miniMIT_Etus 1 fc2\n","miniMIT_Etus 2 fc2\n","(120, 8192)\n","miniMIT_Etus 0 fc2\n","miniMIT_Etus 1 fc2\n","miniMIT_Etus 2 fc2\n","(120, 8192)\n","done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x5MBecexQFEj","colab_type":"text"},"source":["# n=1,2,3 separement"]},{"cell_type":"code","metadata":{"id":"yWsw9rwq_cI6","colab_type":"code","colab":{}},"source":["def get_vlad(doc,layer,n,kmean1,kmean2,pca,type_set=\"train\"):\n","    print(doc, n , layer)\n","    #laod_data\n","    if type_set==\"train\":\n","        x=np.load(dir_path_DataSet + doc + '/' + load_fold + doc +'X_train_'+layer + '(' + str(n) + ').npy')\n","    elif type_set==\"test\":\n","        x=np.load(dir_path_DataSet + doc + '/' + load_fold + doc +'X_test_'+layer + '(' + str(n) + ').npy')\n","\n","\n","    #reshape (d1,d2,d3,d4) -> (d1,d2*d3,d4)\n","    if len(x.shape) == 4:\n","      x = np.reshape(x,(x.shape[0],(x.shape[1]*x.shape[2]),x.shape[3]))\n","    else:\n","      x = np.reshape(x,(x.shape[0],1,x.shape[1]))\n","\n","    #if x_all is empty : x_all take x else add data to x_all \n","\n","    x_all=x\n","                \n","    \n","    V_64=[]\n","    V_256=[]\n","    #for ech image\n","    for vec in x_all:\n","        #we take the first vec and we delete it from the data set: memory problem\n","        x_all=x_all[1:,...]\n","        #normalization l2\n","        vec = normalize(vec, norm = 'l2', axis = 1)\n","        #transformation with PCA\n","        vec=pca.transform(vec)\n","        #normalisation\n","        vec = normalize(vec, norm = 'l2', axis = 1)\n","        \n","        \n","        V_64.append(VLAD(vec,kmean1))\n","        V_256.append(VLAD(vec,kmean2))\n","\n","    \n","    return V_64,V_256\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PFxLnlWjQes","colab_type":"code","outputId":"0f196731-48fc-4d8a-8242-beb8bd8da139","executionInfo":{"status":"ok","timestamp":1557180822344,"user_tz":-120,"elapsed":26506,"user":{"displayName":"CHEN DANG","photoUrl":"https://lh4.googleusercontent.com/-ULtn-wp1jmI/AAAAAAAAAAI/AAAAAAAAAGY/2jasw42jxC8/s64/photo.jpg","userId":"10929130588901207444"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["scales=[1]\n","layers=['fc1','fc2']#,'block8_9_conv']#,'block8_8_conv']\n","for doc in docs:\n","    for layer in layers:\n","        for n in scales:\n","            #load files \n","            kmean1 = pickle.load(open(dir_path_DataSet+doc+'/'+fold_name+doc+'_'+layer+'_'+'n'+str(n)+'_kmean1.pickle', 'rb'))\n","            kmean2 = pickle.load(open(dir_path_DataSet+doc+'/'+fold_name+doc+'_'+layer+'_'+'n'+str(n)+'_kmean2.pickle', 'rb'))\n","            pca = pickle.load(open(dir_path_DataSet+doc + '/' + fold_name+doc+'_'+layer+'_'+'n'+str(n)+'_PCA.pickle', 'rb'))\n","\n","            #lead file for train set\n","            v_train_64,v_train_256=get_vlad(doc,layer,n,kmean1,kmean2,pca,type_set=\"train\")\n","            v_train_64 = np.asarray(v_train_64)\n","            v_train_256= np.asarray(v_train_256)\n","\n","            print(v_train_64.shape)\n","            np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'n'+str(n)+'_vlad_train(64).npy',v_train_64)\n","            np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'n'+str(n)+'_vlad_train(256).npy',v_train_256)\n","            del v_train_64,v_train_256\n","\n","            #for test set\n","            v_test_64,v_test_256=get_vlad(doc,layer,n,kmean1,kmean2,pca,type_set=\"test\")\n","\n","            v_test_64 = np.asarray(v_test_64)\n","            v_test_256= np.asarray(v_test_256)\n","            print(v_test_64.shape)\n","            #save vlad files\n","            np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'n'+str(n)+'_vlad_test(64).npy',v_test_64)\n","            np.save(dir_path_DataSet+doc+'/'+vlad_fold+doc+'_'+layer+'_'+'n'+str(n)+'_vlad_test(256).npy',v_test_256)\n","\n","            print(\"done\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["miniMIT_Etus 1 fc1\n","(120, 8192)\n","miniMIT_Etus 1 fc1\n","(120, 8192)\n","done\n","miniMIT_Etus 1 fc2\n","(120, 8192)\n","miniMIT_Etus 1 fc2\n","(120, 8192)\n","done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"trwGKvwrjQey","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}