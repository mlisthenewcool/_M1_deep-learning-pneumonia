{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_train_cnn_kvasir_v2.ipynb","version":"0.3.2","provenance":[{"file_id":"14DjkJQ59Dc7aM8kfmDVrRGGws8yDeDKI","timestamp":1558341199322},{"file_id":"1QLp_KlwCuNqUpxfVJ69KVcVTx0_gpM1W","timestamp":1558296138331},{"file_id":"1lPXiDWrSN01kFZLBrt3HBAqBEpgaVPll","timestamp":1557911829201}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q5tv4QfdgrMH","colab_type":"text"},"source":["# Train a convolutional neural network"]},{"cell_type":"code","metadata":{"id":"mdhoDRPDMkIV","colab_type":"code","outputId":"94ef9d83-f869-408f-a538-61e47923fcd1","executionInfo":{"status":"ok","timestamp":1558344914595,"user_tz":-120,"elapsed":631,"user":{"displayName":"Hippolyte Debernardi","photoUrl":"","userId":"00537453753370429486"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4TfA2TFHN3Yo","colab_type":"text"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"2CZays-rNNz6","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon May 13 19:35:11 2019\n","\n","@author: hippolyte\n","\"\"\"\n","\n","import os\n","import h5py\n","import imgaug.augmenters as iaa\n","import numpy as np\n","import tensorflow as tf\n","import imgaug as aug\n","import datetime\n","import pickle\n","\n","from keras.applications import vgg16, vgg19, xception\n","from keras.models import Model, Sequential, load_model, save_model\n","from keras.layers import Input, Conv2D, SeparableConv2D, MaxPooling2D, Dense, Dropout, Flatten\n","from keras.layers.normalization import BatchNormalization\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.engine import InputLayer\n","\n","from matplotlib import pyplot as plt\n","from mlxtend.plotting import plot_confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils import class_weight"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"urCTXnRVNzzc","colab_type":"text"},"source":["## Global variables"]},{"cell_type":"code","metadata":{"id":"BHHcC_X0NRTZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":256},"outputId":"16f6f516-e63e-4d5b-8c22-aa8b8944032d","executionInfo":{"status":"error","timestamp":1558344982523,"user_tz":-120,"elapsed":496,"user":{"displayName":"Hippolyte Debernardi","photoUrl":"","userId":"00537453753370429486"}}},"source":["################################################################################\n","### MODIFIABLE VARIABLES\n","################################################################################\n","ROOT_PATH = 'drive/My Drive/master1/medical_image_recognition/'\n","DATASET_NAME = 'kvasir_v2'\n","IMAGE_EXTENSIONS = ['*.jpg', '*.jpeg']\n","\n","################################################################################\n","### DON'T CHANGE THESE VARIABLES\n","################################################################################\n","DATASET_PATH = ROOT_PATH + 'datasets/' + DATASET_NAME + '/'\n","ARRAY_PATH   = ROOT_PATH + 'arrays/'   + DATASET_NAME + '/'\n","MODEL_PATH   = ROOT_PATH + 'models/'   + DATASET_NAME + '/'\n","# create the directory to save arrays if it doesn't exist\n","#! mkdir -pv ARRAY_PATH, MODEL_PATH\n","\n","# get directories and labels\n","DIRECTORIES = sorted([d for d in os.listdir(DATASET_PATH)])\n","LABELS = sorted(os.listdir(DATASET_PATH + DIRECTORIES[0]))\n","# helpers for labels\n","NUM_LABELS = len(LABELS)\n","LABEL_MAPPING = {label: code for code, label in enumerate(LABELS)}\n","# helper for paths\n","PATHS = {directory: DATASET_PATH + directory + '/' for directory in DIRECTORIES}"],"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-833e11fafeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# get directories and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mDIRECTORIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mLABELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDIRECTORIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# helpers for labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/master1/medical_image_recognition/datasets/kvasir_v2/'"]}]},{"cell_type":"code","metadata":{"id":"TJJcteQy0YJE","colab_type":"code","colab":{}},"source":["print(DIRECTORIES)\n","print(LABELS)\n","print(LABEL_MAPPING)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bk2XFvbicMb","colab_type":"text"},"source":["## Fix seeds to have reproducible results\n","\n","https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development"]},{"cell_type":"code","metadata":{"id":"JO1fK7ziiYw5","colab_type":"code","colab":{}},"source":["# the next instructions are used to make results reproducible\n","SEED = 1234\n","os.environ['PYTHONHASHSEED'] = '0'\n","np.random.seed(SEED)\n","tf.set_random_seed(SEED)\n","aug.seed(SEED)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nnBFQ_RNpbL","colab_type":"text"},"source":["## Data function"]},{"cell_type":"code","metadata":{"id":"FEJFInoMMfa3","colab_type":"code","colab":{}},"source":["def label_code_to_str(label_code: int) -> str:\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    for label, code in LABEL_MAPPING.items():\n","        if label_code == code:\n","            return label\n","\n","    raise ValueError('Couldn\\'t find the code {} in labels'.format(label_code))\n","\n","def get_data_dir(directory: str,\n","                 array_dir: str,\n","                 height: int=224,\n","                 width: int=224,\n","                 channels: int=3):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    shape_str = '({},{},{})'.format(height, width, channels)\n","    filename = array_dir + directory + shape_str + '.h5'\n","    print('Getting {} images from {}'.format(shape_str, filename))\n","    \n","    # some helper variables\n","    start = datetime.datetime.now()\n","    \n","    with h5py.File(filename, 'r') as file:\n","        # assuming the file contains same amount of image and labels\n","        num_images = np.ceil(len(file.keys()) / 2).astype(int)\n","\n","        # define arrays holding data and labels\n","        data = np.zeros((num_images, height, width, channels), dtype=np.float32)\n","        labels = np.zeros((num_images, NUM_LABELS), dtype=np.float32)\n","\n","        # iterate over all images\n","        # format is x0 y0 for the first image and so on\n","        for image_index in range(num_images):\n","            image = file['x' + str(image_index)]\n","            label = file['y' + str(image_index)]\n","\n","            data[image_index] = image\n","            labels[image_index] = label\n","\n","    # shapes\n","    print('Data shape : {}\\nLabels shape : {}'.format(data.shape, labels.shape))\n","    \n","    end = datetime.datetime.now()\n","    print('Found {} images in {} seconds.'.format(data.shape[0],\n","                                                 (end-start).seconds))\n","    \n","    return data, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCSpA97oOSFx","colab_type":"text"},"source":["## Convolutional Neural Network functions"]},{"cell_type":"markdown","metadata":{"id":"BsidKQvevVUT","colab_type":"text"},"source":["### Create the network"]},{"cell_type":"code","metadata":{"id":"XLESrsRHNxJ7","colab_type":"code","colab":{}},"source":["def create_vgg19(include_top=True,\n","                 input_shape=(224, 224, 3),\n","                 frozen_layers=None):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    # create the VGG model\n","    vgg19_model = vgg19.VGG19(include_top=include_top,\n","                              weights='imagenet',\n","                              input_shape=input_shape)\n","    # model name\n","    frozen_layers_str = '_'.join(frozen_layers) if frozen_layers else ''\n","    \n","    if include_top is True:\n","        # create a sequential model with corresponding name\n","        model_name = 'vgg19' + frozen_layers_str\n","        model = Sequential(name=model_name)\n","\n","        # add input layer at bottom\n","        model.add(InputLayer(input_shape=input_shape))\n","\n","        # transform the vgg model into sequential\n","        # taking care to not add the last layer containing the dense layer\n","        for layer in vgg19_model.layers[:-1]:\n","            model.add(layer)\n","\n","        # add last layer\n","        model.add(Dense(NUM_LABELS, activation='softmax', name='predictions'))\n","    \n","    else:\n","        # create a sequential model with corresponding name\n","        model_name = 'vgg19_custom' + frozen_layers_str\n","        model = Sequential(name=model_name)\n","        \n","        # add input layer at bottom\n","        model.add(InputLayer(input_shape=input_shape))\n","        \n","        # add the vgg model to model\n","        for layer in vgg19_model.layers:\n","            model.add(layer)\n","        \n","        # add classification block\n","        model.add(Flatten(name='flatten'))\n","        model.add(Dense(1024, activation='relu', name='fc1')) #1024\n","        model.add(Dropout(0.7, name='dropout1'))              #notpresent\n","        model.add(Dense(512, activation='relu', name='fc2'))  #512\n","        model.add(Dropout(0.5, name='dropout2'))              #notpresent\n","        model.add(Dense(NUM_LABELS, activation='softmax', name='predictions'))\n","    \n","    ###################\n","    ### FREEZE PART ###\n","    ###################\n","    \n","    if frozen_layers is None:\n","        print('Everything is trainable.')\n","    \n","    else:\n","        # freeze the first 5 blocks\n","        if 'blocks' in frozen_layers:\n","            for i, layer in enumerate(model.layers):\n","                if layer.name not in ['fc1', 'fc2']:\n","                    layer.trainable = False\n","\n","            print('Froze all blocks before classification one.')\n","\n","        # freeze fc1\n","        if 'fc1' in frozen_layers:\n","            model.get_layer('fc1').trainable = False\n","            print('Froze fc1.')\n","\n","        # freeze fc2\n","        if 'fc2' in frozen_layers:\n","            model.get_layer('fc2').trainable = False\n","            print('Froze fc2.')\n","    \n","    #####################\n","    ### COMPILE MODEL ###\n","    #####################\n","    \n","    loss_type = 'binary' if NUM_LABELS == 2 else 'categorical'\n","    loss_type += '_crossentropy'\n","    optimizer = Adam(lr=1e-6, decay=1e-5)\n","    \n","    model.compile(loss=loss_type,\n","                  metrics=['accuracy'],\n","                  optimizer=optimizer)\n","        \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rWV5aqKHvRJf","colab_type":"text"},"source":["### Training function"]},{"cell_type":"code","metadata":{"id":"iADKjgerhVyZ","colab_type":"code","colab":{}},"source":["def train_model(model,\n","                train_data,\n","                train_labels,\n","                val_data,\n","                val_labels,\n","                epoch=50,\n","                batch_size=32,\n","                metric='val_loss',\n","                save_best_only=True,\n","                save_model_path=None,\n","                save_weights_only=True,\n","                stop_after=5,\n","                save_history=True,\n","                save_history_path=None,\n","                class_weight_mapping=None):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    # callbacks\n","    early_stopping = EarlyStopping(patience=stop_after,\n","                                   monitor=metric,\n","                                   restore_best_weights=True)\n","    \n","    checkpoint = ModelCheckpoint(save_model_path,\n","                                 monitor=metric,\n","                                 verbose=1,\n","                                 save_best_only=save_best_only,\n","                                 save_weights_only=save_weights_only)\n","\n","    # here we are, we'll train the model\n","    history = model.fit(x=train_data,\n","                        y=train_labels,\n","                        batch_size=batch_size,\n","                        epochs=epoch,\n","                        verbose=1,\n","                        callbacks=[early_stopping, checkpoint],\n","                        validation_split=0.0,\n","                        validation_data=(val_data, val_labels),\n","                        shuffle=True,\n","                        class_weight=class_weight_mapping)\n","\n","    # save history\n","    if save_history:\n","        with open(save_history_path, 'wb') as file:\n","            pickle.dump(history.history, file)\n","        print('\\n\\nSaved history into {}'.format(save_history_path))\n","    \n","    return model, history"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Dsr-w9mwDbu","colab_type":"text"},"source":["### Plot results of the network"]},{"cell_type":"code","metadata":{"id":"8bOIp8qgwJMI","colab_type":"code","colab":{}},"source":["def plot_model_performance(model,\n","                           test_data,\n","                           test_labels,\n","                           batch_size=16):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    print('Performances for {} model.'.format(model.name))\n","    print('\\n\\n')\n","    test_loss, test_score = model.evaluate(test_data,\n","                                           test_labels,\n","                                           batch_size=16)\n","    print('Loss : {}'.format(test_loss))\n","    print('Score : {}'.format(test_score))\n","    print('\\n\\n')\n","\n","    # predictions and groud truth\n","    preds = model.predict(test_data, batch_size=16)\n","    preds = np.argmax(preds, axis=-1)\n","    ground_truth = np.argmax(test_labels, axis=-1)\n","    \n","    # confusion matrix\n","    cm  = confusion_matrix(ground_truth, preds)\n","    \n","    # metrics\n","    recall = np.diag(cm) / np.sum(cm, axis=1)\n","    precision = np.diag(cm) / np.sum(cm, axis=0)\n","    accuracy = np.diag(cm) / np.sum(cm)\n","\n","    print('Recall : {}'.format(recall))\n","    print('Precision : {}'.format(precision))\n","    print('Accuracy : {}'.format(accuracy))\n","    print('\\n\\n')\n","\n","    # plot confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cm,\n","                          figsize=(12, 8),\n","                          hide_ticks=True,\n","                          cmap=plt.cm.Blues)\n","    plt.xticks(range(NUM_LABELS), LABELS) #, fontsize=16)\n","    plt.yticks(range(NUM_LABELS), LABELS) #, fontsize=16)\n","    plt.show()\n","    \n","def plot_model_history(history_path):\n","    \"\"\"\n","    TODO\n","    \"\"\"\n","    print('Loading history from {}'.format(history_path))\n","    history = pickle.load(open(history_path, 'rb'))\n","\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4)) #, constrained_layout=True)\n","\n","    # accuracy\n","    axes[0].plot(history['acc'])\n","    axes[0].plot(history['val_acc'])\n","    axes[0].set_title('Model Accuracy')\n","    axes[0].set_ylabel('Accuracy')\n","    axes[0].set_xlabel('Epochs')\n","    axes[0].legend(['train', 'val'])\n","\n","    # loss\n","    axes[1].plot(history['loss'])\n","    axes[1].plot(history['val_loss'])\n","    axes[1].set_title('Model Loss')\n","    axes[1].set_ylabel('Loss')\n","    axes[1].set_xlabel('Epochs')\n","    axes[1].legend(['train', 'val'])\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gvi3bzg5NBxI","colab_type":"text"},"source":["## Let's do it !"]},{"cell_type":"markdown","metadata":{"id":"RJiZgLFSOkLl","colab_type":"text"},"source":["### Data part"]},{"cell_type":"code","metadata":{"id":"ObInMJy7Oi09","colab_type":"code","colab":{}},"source":["HEIGHT, WIDTH, CHANNELS = 224, 224, 3\n","\n","data, labels = dict(), dict()\n","\n","for directory in DIRECTORIES:\n","    # get data and labels\n","    data[directory], labels[directory] = get_data_dir(directory,\n","                                                      array_dir=ARRAY_PATH,\n","                                                      height=HEIGHT,\n","                                                      width=WIDTH,\n","                                                      channels=CHANNELS)\n","    \n","    # get a random index\n","    ind = np.random.randint(data[directory].shape[0])\n","\n","    # plot the image with label\n","    plt.imshow(data[directory][ind])\n","    img_label = np.argmax(labels[directory][ind])\n","    img_label_str = label_code_to_str(img_label)\n","    #plt.title(img_label_str, img_label)\n","    print('{}({})'.format(img_label, img_label_str))\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5WbeF82IOn7g","colab_type":"text"},"source":["### CNN creation"]},{"cell_type":"code","metadata":{"id":"xGYKscVVM-gP","colab_type":"code","colab":{}},"source":["model = create_vgg19(include_top=True,\n","                     input_shape=(HEIGHT, WIDTH, CHANNELS),\n","                     frozen_layers=None)\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1wmN5w-QOx5l","colab_type":"text"},"source":["### CNN training\n","#### USE IT WITH CAUTION, IT CAN TAKE TIME"]},{"cell_type":"code","metadata":{"id":"qUJptuDaGtlo","colab_type":"code","colab":{}},"source":["CLASS_WEIGHT_MAPPING = None #{0: 1, 1: 0.3473548387096774}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-byiwSIAOtzl","colab_type":"code","colab":{}},"source":["SAVE_MODEL_PATH = MODEL_PATH + model.name + '_model2.hdf5'\n","SAVE_HISTORY_PATH = MODEL_PATH + model.name + '_history2'\n","\n","model, history = train_model(model,\n","                             train_data=data['train'],\n","                             train_labels=labels['train'],\n","                             val_data=data['test'],\n","                             val_labels=labels['test'],\n","                             epoch=300,\n","                             batch_size=32,\n","                             metric='val_acc',\n","                             save_best_only=True,\n","                             save_model_path=SAVE_MODEL_PATH,\n","                             save_weights_only=False,\n","                             stop_after=100,\n","                             save_history=True,\n","                             save_history_path=SAVE_HISTORY_PATH,\n","                             class_weight_mapping=CLASS_WEIGHT_MAPPING)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uR-tiA6kqNoG","colab_type":"code","colab":{}},"source":["plot_model_performance(model,\n","                       test_data=data['test'],\n","                       test_labels=labels['test'],\n","                       batch_size=32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6CfC3mv7njP","colab_type":"code","colab":{}},"source":["plot_model_history(SAVE_HISTORY_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NxBCvG4EWphM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}