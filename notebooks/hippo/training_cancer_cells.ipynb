{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training_cancer_cells.ipynb","version":"0.3.2","provenance":[{"file_id":"1eJnt9kjEkk-bqis6frwEZG0u---Tf3Rl","timestamp":1558703802646},{"file_id":"1gj3RNvINAypwOBHr0JLLwWZHsttFm2nT","timestamp":1558640306792}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gcprsM2fvEVk","colab_type":"code","outputId":"91f6f611-9bca-4f57-b27c-8fb658a1f25e","executionInfo":{"status":"error","timestamp":1562425028992,"user_tz":-120,"elapsed":389621,"user":{"displayName":"Hippolyte Debernardi","photoUrl":"https://lh3.googleusercontent.com/-iO2hFrrSmY4/AAAAAAAAAAI/AAAAAAAAApU/GhCEzGFYTwM/s64/photo.jpg","userId":"00537453753370429486"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"source":["from google.colab import drive, files\n","drive.mount('drive')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-494f6b76af7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendcontrol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"iIUAcZbZvHvh","colab_type":"code","colab":{}},"source":["from keras import applications\n","from keras import optimizers\n","from keras.models import Model\n","from keras.layers import (\n","    Dropout, Flatten, Dense, InputLayer, SeparableConv2D, BatchNormalization,\n","    MaxPooling2D)\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajQSSYMFvcQ_","colab_type":"code","colab":{}},"source":["DATA_AUGMENTATION = True\n","DATASET_NAME = 'cancer_cells'\n","\n","ROOT_PATH    = 'drive/My Drive/master1/medical_image_recognition/'\n","DATASET_PATH = ROOT_PATH + 'datasets/' + DATASET_NAME + '/'\n","MODEL_PATH   = ROOT_PATH + 'models/'   + DATASET_NAME + '/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOm8RTNmNFcj","colab_type":"code","colab":{}},"source":["def get_generator(directory,\n","                  image_shape=(224, 224),\n","                  batch_size=32,\n","                  should_augment=False,\n","                  data_gen_args=None):\n","    \n","    # only rescale\n","    if should_augment is False:\n","        image_gen = ImageDataGenerator(rescale=(1./255))\n","    \n","    # use dictionary to define augmentations\n","    else:\n","        if data_gen_args is None:\n","            data_gen_args = dict(rescale=1./255,\n","                                 shear_range=0.2,\n","                                 zoom_range=0.2,\n","                                 horizontal_flip=True)\n","        \n","        image_gen = ImageDataGenerator(**data_gen_args)\n","    \n","    return image_gen.flow_from_directory(directory,\n","                                         target_size=image_shape,\n","                                         batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnwwrSiNVGJ_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aApe8l4PwRoA","colab_type":"code","outputId":"7f65948d-05a2-4165-d46c-f2d57c284a70","executionInfo":{"status":"ok","timestamp":1558796149947,"user_tz":-120,"elapsed":2676,"user":{"displayName":"Hippolyte Debernardi","photoUrl":"","userId":"00537453753370429486"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["HEIGHT, WIDTH, CHANNELS = 224, 224, 3\n","BATCH_SIZE = 32\n","\n","train_generator = get_generator(DATASET_PATH + 'train',\n","                                batch_size=BATCH_SIZE,\n","                                should_augment=DATA_AUGMENTATION)\n","\n","test_generator = get_generator(DATASET_PATH + 'val',\n","                               batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 145 images belonging to 2 classes.\n","Found 48 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"68ZwZRwgw5J4","colab_type":"code","colab":{}},"source":["def build_model_bis(image_shape,\n","                    classes,\n","                    num_layers_from_vgg=11):\n","    \n","\n","    model_name = f'vgg19_depthwise_{num_layers_from_vgg}'\n","    \n","    # build vgg 19 model\n","    vgg = applications.vgg19.VGG19(input_shape=image_shape,\n","                                   weights='imagenet',\n","                                   include_top=False)\n","    print('Load VGG19 as base model')\n","    \n","    # block 4\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_sepconv1')(vgg.layers[num_layers_from_vgg].output)\n","    x = BatchNormalization(name='block4_conv1_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_sepconv2')(x)\n","    x = BatchNormalization(name='block4_conv2_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block4_sepconv3')(x)\n","    x = MaxPooling2D((2, 2), name='block4_pool')(x)\n","    \n","    # block 5\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block5_sepconv1')(x)\n","    x = BatchNormalization(name='block5_conv1_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block5_sepconv2')(x)\n","    x = BatchNormalization(name='block5_conv2_bn')(x)\n","    x = SeparableConv2D(512, (3, 3),\n","                        activation='relu',\n","                        padding='same',\n","                        name='block5_sepconv3')(x)\n","    x = MaxPooling2D((2, 2), name='block5_pool')(x)\n","    \n","    print('Load blocks 4 and 5')\n","\n","    # adding classification block on top\n","    x = Flatten(input_shape=image_shape, name='flatten')(x)\n","    x = Dense(1024, activation='relu', name='fc1')(x)\n","    x = Dropout(0.7, name='dropout1')(x)\n","    x = Dense(512, activation='relu', name='fc2')(x)\n","    x = Dropout(0.5, name='dropout2')(x)\n","    x = Dense(classes, activation='softmax', name='predictions')(x)\n","    \n","    # combine both\n","    model = Model(inputs=vgg.input, outputs=x, name=model_name)\n","    \n","    # load top model weights\n","    #model.load_weights(top_model_weights_path)\n","    \n","    # freeze layers\n","    for i, layer in enumerate(model.layers):\n","        if i <= num_layers_from_vgg:\n","            layer.trainable = False\n","        else:\n","            layer.trainable = True\n","            print(f'Layer {i} {layer.name} is trainable')\n","\n","    # compile model\n","    loss_type = 'binary_' if classes == 2 else 'categorical_'\n","    loss_type += 'crossentropy'\n","    model.compile(loss=loss_type,\n","                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n","                  metrics=['accuracy'])\n","    \n","    print('Model compiled')\n","    return model\n","    \n","def build_model(image_shape,\n","                classes,\n","                num_layers_to_freeze=21,\n","                base_model_weights_path=None,\n","                top_model_weights_path=None):\n","    \n","    model_name = f'vgg19_{num_layers_to_freeze}'\n","    \n","    # build the base model\n","    if base_model_weights_path is None:\n","        base_model_weights_path = 'imagenet'\n","    base_model = applications.vgg19.VGG19(input_shape=image_shape,\n","                                          weights=base_model_weights_path,\n","                                          include_top=False)\n","    print('Load VGG19 as base model')\n","    \n","    # load base model weights\n","    #base_model.load_weights(base_model_weights_path)\n","    \n","    # adding classification block on top of base model\n","    x = Flatten(input_shape=image_shape, name='flatten')(base_model.output)\n","    x = Dense(512, activation='relu', name='fc1')(x)\n","    x = Dropout(0.7, name='dropout1')(x)\n","    x = Dense(256, activation='relu', name='fc2')(x)\n","    x = Dropout(0.5, name='dropout2')(x)\n","    x = Dense(classes, activation='softmax', name='predictions')(x)\n","    \n","    # combine both\n","    model = Model(inputs=base_model.input, outputs=x, name=model_name)\n","    \n","    # load top model weights\n","    #model.load_weights(top_model_weights_path)\n","    \n","    # freeze layers\n","    for i, layer in enumerate(model.layers):\n","        if i <= num_layers_to_freeze:\n","            layer.trainable = False\n","        else:\n","            layer.trainable = True\n","            print(f'Layer {i} {layer.name} is trainable')\n","\n","    # compile model\n","    loss_type = 'binary_' if classes == 2 else 'categorical_'\n","    loss_type += 'crossentropy'\n","    model.compile(loss=loss_type,\n","                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n","                  metrics=['accuracy'])\n","    \n","    print('Model compiled')\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ID3Wt-SZyoSq","colab_type":"code","outputId":"a91bd4f2-cc11-4aa8-92d9-5de5c7fc1c52","executionInfo":{"status":"ok","timestamp":1558796158961,"user_tz":-120,"elapsed":1866,"user":{"displayName":"Hippolyte Debernardi","photoUrl":"","userId":"00537453753370429486"}},"colab":{"base_uri":"https://localhost:8080/","height":1513}},"source":["#BASE_MODEL_WEIGHTS_PATH = ROOT_PATH + 'models/vgg19_weights_no_top.h5'\n","NUM_CLASSES = len(train_generator.class_indices)\n","\n","#model = build_model(image_shape=(HEIGHT, WIDTH, CHANNELS), classes=NUM_CLASSES)\n","model = build_model_bis(image_shape=(HEIGHT, WIDTH, CHANNELS), classes=NUM_CLASSES)\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Load VGG19 as base model\n","Load blocks 4 and 5\n","Layer 12 block4_sepconv1 is trainable\n","Layer 13 block4_conv1_bn is trainable\n","Layer 14 block4_sepconv2 is trainable\n","Layer 15 block4_conv2_bn is trainable\n","Layer 16 block4_sepconv3 is trainable\n","Layer 17 block4_pool is trainable\n","Layer 18 block5_sepconv1 is trainable\n","Layer 19 block5_conv1_bn is trainable\n","Layer 20 block5_sepconv2 is trainable\n","Layer 21 block5_conv2_bn is trainable\n","Layer 22 block5_sepconv3 is trainable\n","Layer 23 block5_pool is trainable\n","Layer 24 flatten is trainable\n","Layer 25 fc1 is trainable\n","Layer 26 dropout1 is trainable\n","Layer 27 fc2 is trainable\n","Layer 28 dropout2 is trainable\n","Layer 29 predictions is trainable\n","Model compiled\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_sepconv1 (SeparableCo (None, 28, 28, 512)       133888    \n","_________________________________________________________________\n","block4_conv1_bn (BatchNormal (None, 28, 28, 512)       2048      \n","_________________________________________________________________\n","block4_sepconv2 (SeparableCo (None, 28, 28, 512)       267264    \n","_________________________________________________________________\n","block4_conv2_bn (BatchNormal (None, 28, 28, 512)       2048      \n","_________________________________________________________________\n","block4_sepconv3 (SeparableCo (None, 28, 28, 512)       267264    \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_sepconv1 (SeparableCo (None, 14, 14, 512)       267264    \n","_________________________________________________________________\n","block5_conv1_bn (BatchNormal (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","block5_sepconv2 (SeparableCo (None, 14, 14, 512)       267264    \n","_________________________________________________________________\n","block5_conv2_bn (BatchNormal (None, 14, 14, 512)       2048      \n","_________________________________________________________________\n","block5_sepconv3 (SeparableCo (None, 14, 14, 512)       267264    \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 1024)              25691136  \n","_________________________________________________________________\n","dropout1 (Dropout)           (None, 1024)              0         \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 512)               524800    \n","_________________________________________________________________\n","dropout2 (Dropout)           (None, 512)               0         \n","_________________________________________________________________\n","predictions (Dense)          (None, 2)                 1026      \n","=================================================================\n","Total params: 30,020,930\n","Trainable params: 27,691,266\n","Non-trainable params: 2,329,664\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dt_KyaAPvFHp","colab_type":"code","colab":{}},"source":["# fine-tune the model\n","EPOCHS = 300\n","TRAIN_LEN = train_generator.n\n","TEST_LEN = test_generator.n\n","CLASS_WEIGHT = None#{0: 1.0, 1: 0.4}\n","\n","SAVE_HISTORY_PATH = MODEL_PATH + model.name + '.history'\n","SAVE_MODEL_PATH   = MODEL_PATH + model.name + '.model'\n","\n","import pickle\n","\n","def train_model(save_model_path,\n","                save_history_path,\n","                save_history=True):\n","    \n","    early_stopping = EarlyStopping(patience=20,\n","                                   monitor='val_loss',\n","                                   restore_best_weights=True)\n","\n","    checkpoint = ModelCheckpoint(save_model_path,\n","                                 monitor='val_loss',\n","                                 verbose=1,\n","                                 save_best_only=True,\n","                                 save_weights_only=False)\n","\n","    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","    #                              patience=5, min_lr=0.001)\n","\n","    history = model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=TRAIN_LEN, # //  BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=test_generator,\n","        validation_steps=TEST_LEN, # // BATCH_SIZE,\n","        verbose=1,\n","        callbacks=[early_stopping, checkpoint],\n","        class_weight=CLASS_WEIGHT)\n","\n","    # save history\n","    if save_history:\n","        with open(save_history_path, 'wb') as file:\n","            pickle.dump(history.history, file)\n","        print(f'\\n\\nSaved history into {save_history_path}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JinJp7qExvm","colab_type":"code","outputId":"5d7b3cc4-ff1c-47c4-ac9e-7c8cefa7f6d9","colab":{"base_uri":"https://localhost:8080/","height":819}},"source":["train_model(save_model_path=SAVE_MODEL_PATH,\n","            save_history_path=SAVE_HISTORY_PATH)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/300\n","145/145 [==============================] - 1257s 9s/step - loss: 0.6930 - acc: 0.5149 - val_loss: 0.6930 - val_acc: 0.6042\n","\n","Epoch 00001: val_loss improved from inf to 0.69298, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 2/300\n","145/145 [==============================] - 1117s 8s/step - loss: 0.6925 - acc: 0.5342 - val_loss: 0.6925 - val_acc: 0.6042\n","\n","Epoch 00002: val_loss improved from 0.69298 to 0.69253, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 3/300\n","145/145 [==============================] - 1104s 8s/step - loss: 0.6920 - acc: 0.5677 - val_loss: 0.6920 - val_acc: 0.6667\n","\n","Epoch 00003: val_loss improved from 0.69253 to 0.69204, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 4/300\n","145/145 [==============================] - 1115s 8s/step - loss: 0.6916 - acc: 0.5822 - val_loss: 0.6915 - val_acc: 0.6875\n","\n","Epoch 00004: val_loss improved from 0.69204 to 0.69152, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 5/300\n","145/145 [==============================] - 1129s 8s/step - loss: 0.6909 - acc: 0.5964 - val_loss: 0.6910 - val_acc: 0.6875\n","\n","Epoch 00005: val_loss improved from 0.69152 to 0.69096, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 6/300\n","145/145 [==============================] - 1114s 8s/step - loss: 0.6903 - acc: 0.6072 - val_loss: 0.6904 - val_acc: 0.6458\n","\n","Epoch 00006: val_loss improved from 0.69096 to 0.69044, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 7/300\n","145/145 [==============================] - 1086s 7s/step - loss: 0.6899 - acc: 0.6176 - val_loss: 0.6898 - val_acc: 0.6458\n","\n","Epoch 00007: val_loss improved from 0.69044 to 0.68980, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 8/300\n","145/145 [==============================] - 1087s 7s/step - loss: 0.6892 - acc: 0.6233 - val_loss: 0.6892 - val_acc: 0.7083\n","\n","Epoch 00008: val_loss improved from 0.68980 to 0.68916, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 9/300\n","145/145 [==============================] - 1105s 8s/step - loss: 0.6885 - acc: 0.6234 - val_loss: 0.6884 - val_acc: 0.6875\n","\n","Epoch 00009: val_loss improved from 0.68916 to 0.68844, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 10/300\n","145/145 [==============================] - 1080s 7s/step - loss: 0.6878 - acc: 0.6331 - val_loss: 0.6875 - val_acc: 0.6875\n","\n","Epoch 00010: val_loss improved from 0.68844 to 0.68752, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 11/300\n","145/145 [==============================] - 1077s 7s/step - loss: 0.6867 - acc: 0.6542 - val_loss: 0.6865 - val_acc: 0.6875\n","\n","Epoch 00011: val_loss improved from 0.68752 to 0.68649, saving model to drive/My Drive/master1/medical_image_recognition/models/cancer_cells/vgg19_depthwise_11.model\n","Epoch 12/300\n","143/145 [============================>.] - ETA: 11s - loss: 0.6856 - acc: 0.6537"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D45M5Gf5Vyn6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}