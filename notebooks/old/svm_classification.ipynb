{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Bt2dPiQeYSYM",
    "outputId": "1374afd4-be9d-4a40-de5b-99c642551225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-DoQUB4BwuL2",
    "outputId": "d5252878-2f7c-40ce-f348-8da68991d20b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed\n",
    "from keras.layers import AveragePooling2D, Input\n",
    "from keras.utils import np_utils, normalize\n",
    "from keras.engine import InputLayer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "import time\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def pool(X, p):\n",
    "  \"\"\"return the numpy array X on which the pooling p was performed\"\"\"\n",
    "  if p == 'max' :  \n",
    "    X_pool = np.max(X, axis = (1, 2)) \n",
    "  elif p == 'mean' :\n",
    "    X_pool = np.mean(X, axis = (1, 2)) \n",
    "  else :\n",
    "    X_pool = X\n",
    "  return X_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_5FkGl3mW_q"
   },
   "outputs": [],
   "source": [
    "#dataset's folds  \n",
    "save_flod=''\n",
    "\n",
    "#dataset's path \n",
    "dir_path_DataSet='drive/My Drive/M2_IAAA/ter/DataSet/'\n",
    "\n",
    "\n",
    "docs=['chest_xray','miniMIT_Etus','kvasir-dataset-v2']\n",
    "scales=[0,1,2]\n",
    "layers=['block5_pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSXubPKPrU9z"
   },
   "outputs": [],
   "source": [
    "\n",
    "for doc in docs:\n",
    "  for n in scales:\n",
    "    for layer in layers:\n",
    "      \n",
    "      print(doc, n , layer)\n",
    "      #laod_data\n",
    "      \n",
    "      x_train=np.load(dir_path_DataSet + save_flod + doc +'X_train_'+layer + '(' + str(n) + ').npy')\n",
    "      x_test=np.load( dir_path_DataSet + save_flod + doc +'X_test_'+layer + '(' + str(n) + ').npy')\n",
    "      y_train=np.load(dir_path_DataSet + save_flod + doc +'Y_train_'+layer + '(' + str(n) + ').npy')\n",
    "      y_test=np.load( dir_path_DataSet + save_flod + doc +'Y_test_'+layer + '(' + str(n) + ').npy')\n",
    "\n",
    "      print(x_train.shape)\n",
    "      print(x_test.shape)\n",
    "      print(y_train.shape)\n",
    "      print(y_test.shape)\n",
    "      #pooling performed on the output : max, mean, or not\n",
    "      pooling = 'mean'\n",
    "\n",
    "      if layer == 'block5_pool' or n>0 :\n",
    "        #pooling\n",
    "        x_train = pool(x_train, pooling)\n",
    "        x_test = pool(x_test, pooling)\n",
    "\n",
    "      #normalization\n",
    "      x_train = sklearn.preprocessing.normalize(x_train, norm = 'l2', axis = 1)\n",
    "      x_test = sklearn.preprocessing.normalize(x_test, norm = 'l2', axis = 1)\n",
    "      \n",
    "      print(x_train.shape)\n",
    "      print(x_test.shape)\n",
    "      print(y_train.shape)\n",
    "      print(y_test.shape)\n",
    "   \n",
    "\n",
    "      print('prediction SVM [%s,%s,%s]'%(doc,n,layer))\n",
    "      \n",
    "      \"\"\"SUPPORT VECTOR MACHINE\"\"\"\n",
    "\n",
    "      parameters = {'C':[0.0001,0.001,0.01, 0.1, 1, 10,100]}\n",
    "      clf = SVC(kernel='linear')\n",
    "      clf = GridSearchCV(clf, parameters, cv=3,n_jobs=-1)\n",
    "      clf.fit(x_train, y_train)\n",
    "\n",
    "      print('Accuracy: %.2f' % clf.score(x_test, y_test))\n",
    "\n",
    "      print('Done')\n",
    "      \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "svm_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
