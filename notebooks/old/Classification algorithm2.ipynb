{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification algorithm2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"Bt2dPiQeYSYM","colab":{}},"cell_type":"code","source":["# mount the drive to access to data files\n","from google.colab import drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-DoQUB4BwuL2","colab":{}},"cell_type":"code","source":["import keras\n","\n","from keras import backend as K\n","\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing import image\n","\n","from keras.models import Sequential\n","from keras.models import Model\n","\n","from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda\n","from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed\n","from keras.layers import AveragePooling2D, Input\n","\n","from keras.applications.vgg19 import VGG19\n","from keras.applications.vgg19 import preprocess_input\n","\n","from keras.utils import np_utils, normalize\n","from keras.engine import InputLayer\n","\n","################################################################################\n","import sklearn\n","\n","from sklearn.preprocessing import normalize\n","from sklearn.linear_model import SGDClassifier\n","\n","################################################################################\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy.io as sio\n","\n","import os\n","import h5py\n","import glob\n","import time\n","\n","################################################################################\n","\n","def read_dir(dir_path) :\n","  \"\"\"return the differents categories, the images in these categories, and the number of images per category\"\"\"\n","  listDir = sorted(os.listdir(dir_path))\n","  sizes = []\n","  listFiles = []\n","  for d in listDir :\n","    files = sorted(os.listdir(dir_path+'/'+d))\n","    sizes += [len(files)]\n","    listFiles += [files]\n","  return listDir, listFiles, sizes\n","\n","\n","def create_zero_array(layer, n, nb_images):\n","  \"\"\"return a numpy array with zeros and with the needed scales\"\"\"\n","  if layer == 'block5_pool' :\n","    X = np.zeros((nb_images, 7 + 10*n, 7 + 10*n, 512))\n","  else :\n","    if n == 0 :\n","      X = np.zeros((nb_images, 4096))\n","    else :\n","      X = np.zeros((nb_images, -3 + 5*n, -3 + 5*n, 4096))\n","  return X\n","  \n","\n","def complete_array(dir_path, dir_save, listDir, listFiles, X, n) :\n","  \"\"\"for all the images in listFiles, extract the features thanks to the network\"\"\"\n","  \"\"\"return a 4-dimensional array with a 3-dimensional array per image\"\"\"\n","  X_new = X\n","  nb = 0\n","  cpt = 0\n","  t0 = time.time()\n","  for i in range (len(listDir)) :\n","    d = listDir[i]\n","    files = listFiles[i]\n","    print(d, len(files))\n","    nb += len(files)\n","    for f in files :\n","      t1 = time.time()\n","      img = image.load_img(dir_path+'/'+d+'/'+f, target_size=(224 + 320*n, 224 + 320*n))\n","      x = image.img_to_array(img)\n","      x = np.expand_dims(x, axis=0)\n","      x = preprocess_input(x)\n","      features = network2.predict(x)\n","      X_new[cpt,:] = features[0,:]\n","      cpt += 1\n","      t2 = time.time()\n","      print(str(cpt) + '/' + str(nb), t2 - t1)\n","    np.save(dir_save, X_new)\n","  print('total', t2 - t0)\n","  return X_new\n","\n","def pool(X, p):\n","  \"\"\"return the numpy array X on which the pooling p was performed\"\"\"\n","  if p == 'max' :  \n","    X_pool = np.max(X, axis = (1, 2)) \n","  elif p == 'mean' :\n","    X_pool = np.mean(X, axis = (1, 2)) \n","  else :\n","    X_pool = X\n","  return X_pool\n","\n","\n","def to_fully_conv(model):\n","  \"\"\"transforms the Convolutional Neural Network model into a Fully Convolutional Network\"\"\"\n","\n","    new_model = Sequential()\n","\n","    input_layer = InputLayer(input_shape=(None, None, 3), name=\"input_new\")\n","\n","    new_model.add(input_layer)\n","\n","    for layer in model.layers:\n","\n","        if \"Flatten\" in str(layer):\n","            flattened_ipt = True\n","            f_dim = layer.input_shape\n","\n","        elif \"Dense\" in str(layer):\n","\n","            input_shape = layer.input_shape\n","            output_dim =  layer.get_weights()[1].shape[0]\n","            W,b = layer.get_weights()\n","\n","            if flattened_ipt:\n","                shape = (f_dim[1],f_dim[2],f_dim[3],output_dim)\n","                new_W = W.reshape(shape)\n","                new_layer = Convolution2D(output_dim,\n","                                          (f_dim[1],f_dim[2]),\n","                                          strides=(1,1),\n","                                          activation=layer.activation,\n","                                          padding='valid',\n","                                          weights=[new_W,b])\n","                flattened_ipt = False\n","\n","            else:\n","                shape = (1,1,input_shape[1],output_dim)\n","                new_W = W.reshape(shape)\n","                new_layer = Convolution2D(output_dim,\n","                                          (1,1),\n","                                          strides=(1,1),\n","                                          activation=layer.activation,\n","                                          padding='valid',\n","                                          weights=[new_W,b])\n","\n","\n","        else:\n","            new_layer = layer\n","\n","        new_model.add(new_layer)\n","\n","    return new_model\n","  \n","\n","\n","      \n","print('Done')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"uF13YyMdsXau","colab":{}},"cell_type":"code","source":["\n","\n","#layer from which we take the output : block5_pool, fc1 or fc2\n","layer = 'block5_pool'\n","\n","#name of the document where the train and test set are stocked\n","doc = ''\n","\n","#scale of images = (224 + 320n)*(224+320n)\n","n = 0\n","\n","#pooling performed on the output : max, mean, or not\n","pooling = 'mean'\n","\n","\n","#definition of the network used (VGG19)\n","network = VGG19(weights='imagenet')#, input_shape=(fscale, fscale, 3))\n","network2 = Model(inputs=network.input, outputs=network.get_layer(layer).output)\n","if n >= 1 : \n","  network2 = to_fully_conv(network2)\n","\n","################################################################################\n","\n","\"\"\"ARTIFICIAL NEURAL NETWORK\"\"\"\n","\n","#path where train images and test images are stocked\n","dir_path_train = 'drive/My Drive/Datasets/' + doc + '/train'\n","dir_path_test = 'drive/My Drive/Datasets/'+doc+'/test'\n","\n","#path where the output array will be saved\n","save_train = 'drive/My Drive/Datasets/' + doc + '/X_train_' + layer + '_' + pooling + '(' + str(n) + ').npy'\n","save_test = 'drive/My Drive/Datasets/' + doc + '/X_test_' + layer + '_' + pooling + '(' + str(n) + ').npy'\n","\n","#creating numpy array from images\n","listDir_train, listFiles_train, sizes_train = read_dir(dir_path_train)\n","listDir_test, listFiles_test, sizes_test = read_dir(dir_path_test)\n","\n","X_train = create_zero_array(layer, n, sum(sizes_train))\n","X_test = create_zero_array(layer, n, sum(sizes_test))\n","\n","X_train = complete_array(dir_path_train, save_train, listDir_train, listFiles_train, X_train, n)\n","X_test = complete_array(dir_path_test, save_test, listDir_test, listFiles_test, X_test, n)\n","\n","#pooling\n","X_train = pool(X_train, pooling)\n","X_test = pool(X_test, pooling)\n","\n","#normalization\n","X_train = sklearn.preprocessing.normalize(X_train, norm = 'l2', axis = 1)\n","X_test = sklearn.preprocessing.normalize(X_test, norm = 'l2', axis = 1)\n","\n","\n","\"\"\"SUPPORT VECTOR MACHINE\"\"\"\n","\n","print(X_train.shape, X_test.shape)\n","\n","parameters = {'C':[0.0001,0.001,0.01, 0.1, 1, 10,100]}\n","svr = svm.SVC(kernel='linear')\n","clf = GridSearchCV(svr, parameters, cv=3)\n","clf.fit(X_train, Y_train)\n","\n","print('Accuracy: %.2f' % clf.score(X_test, Y_test))\n","\n","print('Done')\n","\n"],"execution_count":0,"outputs":[]}]}