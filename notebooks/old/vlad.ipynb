{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VLAD(X,visualDictionary):\n",
    "\n",
    "    predictedLabels = visualDictionary.predict(X)\n",
    "    centers = visualDictionary.cluster_centers_\n",
    "    labels=visualDictionary.labels_\n",
    "    k=visualDictionary.n_clusters\n",
    "\n",
    "    m,d = X.shape\n",
    "    \n",
    "    \n",
    "    V=np.zeros([k,d])\n",
    "    #computing the differences\n",
    "\n",
    "    # for all the clusters (visual words)\n",
    "    for i in range(k):\n",
    "        # if there is at least one descriptor in that cluster\n",
    "        if np.sum(predictedLabels==i)>0:\n",
    "            # add the diferences\n",
    "            V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\n",
    "\n",
    "\n",
    "    V = V.flatten()\n",
    "    # power normalization, also called square-rooting normalization\n",
    "    V = np.sign(V)*np.sqrt(np.abs(V))\n",
    "\n",
    "    # L2 normalization\n",
    "\n",
    "    V = V/np.sqrt(np.dot(V,V))\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"train\"):\n",
    "    for n in scales:\n",
    "        print(doc, n , layer)\n",
    "        #laod_data\n",
    "        if type_set==\"train\":\n",
    "            x=np.load(dir_path_DataSet + load_flod + doc +'X_train_'+layer + '(' + str(n) + ').npy')\n",
    "        elif type_set==\"test\":\n",
    "            x=np.load(dir_path_DataSet + load_flod + doc +'X_test_'+layer + '(' + str(n) + ').npy')\n",
    "            \n",
    "\n",
    "        if layer==\"block5_pool\" or n!=0:\n",
    "            #reshape (d1,d2,d3,d4) -> (d1,d2*d3,d4)\n",
    "            x = np.reshape(x,(x.shape[0],(x.shape[1]*x.shape[2]),x.shape[3]))\n",
    "\n",
    "            #if x_all is empty : x_all take x else add data to x_all \n",
    "            if(n==0):\n",
    "                x_all=x\n",
    "\n",
    "            else:\n",
    "                x_all=np.concatenate((x_all,x),axis=1)\n",
    "                \n",
    "    \n",
    "    V_64=[]\n",
    "    V_256=[]\n",
    "    #for ech image\n",
    "    for vec in x_all:\n",
    "        #we take the first vec and we delete it from the data set: memory problem\n",
    "        x_all=x_all[1:,...]\n",
    "        #normalization l2\n",
    "        vec = normalize(vec, norm = 'l2', axis = 1)\n",
    "        #transformation with PCA\n",
    "        vec=pca.transform(vec)\n",
    "        #normalisation\n",
    "        vec = normalize(vec, norm = 'l2', axis = 1)\n",
    "        \n",
    "        \n",
    "        V_64.append(VLAD(vec,kmean1))\n",
    "        V_256.append(VLAD(vec,kmean2))\n",
    "\n",
    "    \n",
    "    return V_64,V_256\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_flod='dataNpVGG/'\n",
    "save_flod='fold_kvasir/'\n",
    "#dataset's path \n",
    "dir_path_DataSet=''\n",
    "\n",
    "ter_path=\"\"\n",
    "#fold name for saving files(kmean/PCA)\n",
    "fold_name=\"files/\"\n",
    "vlad_fold=\"vlad_fold/\"\n",
    "\n",
    "docs=['miniMIT_Etus']#,'chest_xray','kvasir-dataset-v2']\n",
    "scales=[0,1,2]\n",
    "layers=['block5_pool']#,'block8_9_conv']#,'block8_8_conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    for layer in layers:\n",
    "        #load files \n",
    "        kmean1 = pickle.load(open(ter_path+fold_name+doc+'_'+layer+'_'+'kmean1.pickle', 'rb'))\n",
    "        kmean2 = pickle.load(open(ter_path+fold_name+doc+'_'+layer+'_'+'kmean2.pickle', 'rb'))\n",
    "        pca = pickle.load(open(ter_path+fold_name+doc+'_'+layer+'_'+'PCA.pickle', 'rb'))\n",
    "        \n",
    "        #lead file for train set\n",
    "        v_train_64,v_train_256=get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"train\")\n",
    "        v_train_64 = np.asarray(v_train_64)\n",
    "        v_train_256= np.asarray(v_train_256)\n",
    "        \n",
    "        print(v_train_64.shape)\n",
    "        np.save(ter_path+vlad_fold+doc+'_'+layer+'_'+'vlad_train(64).npy',v_train_64)\n",
    "        np.save(ter_path+vlad_fold+doc+'_'+layer+'_'+'vlad_train(256).npy',v_train_256)\n",
    "        del v_train_64,v_train_256\n",
    "        \n",
    "        #for test set\n",
    "        v_test_64,v_test_256=get_vlad(doc,layer,scales,kmean1,kmean2,pca,type_set=\"test\")\n",
    "        \n",
    "        v_test_64 = np.asarray(v_test_64)\n",
    "        v_test_256= np.asarray(v_test_256)\n",
    "        print(v_test_64.shape)\n",
    "        #save vlad files\n",
    "        np.save(ter_path+vlad_fold+doc+'_'+layer+'_'+'vlad_test(64).npy',v_test_64)\n",
    "        np.save(ter_path+vlad_fold+doc+'_'+layer+'_'+'vlad_test(256).npy',v_test_256)\n",
    "        \n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
